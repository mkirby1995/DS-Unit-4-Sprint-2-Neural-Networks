{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkirby1995/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Assignments/LS_DS_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVfaLrjLvxvQ",
        "colab_type": "text"
      },
      "source": [
        "# Intro to Neural Networks Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxtoY12mwmih",
        "colab_type": "text"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer: The visable layer of a network that interacts directly with the feed data\n",
        "### Hidden Layer: Layers after the input layer that cannot be accessed except through the input layer\n",
        "### Output Layer: The final layer that outputs a vector of answers\n",
        "### Neuron: A representation of a transformation to the previous layers value\n",
        "### Weight: The scalar value assigned to an input value in a layer\n",
        "### Activation Function: A function for transforming the output of a neuron\n",
        "### Node Map: A visual representation of the structure of a neural netwoks layers\n",
        "### Perceptron: A neural network with a single layer \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXuy9WcWzxa4",
        "colab_type": "text"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlSwIJMC0A8F",
        "colab_type": "text"
      },
      "source": [
        "#### The data is fed into an input node where it is then transformed by computing the dot product between the inputs and the weights, this is then combined with a bias value and the result is fed theough am activation function. The process repeats for each node in the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sWR43PTwhSk",
        "colab_type": "text"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgh7VFGwnXGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "inputs = np.array([\n",
        "    [0,0,1],\n",
        "    [1,0,1],\n",
        "    [0,1,1],\n",
        "    [1,1,0]\n",
        "])\n",
        "\n",
        "correct_outputs = [[0], [1], [1], [0]]\n",
        "\n",
        "weights = 2 * np.random.random((3, 1)) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoK6BxXmyEoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGZ-_o1HyUNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "62d1c2fc-e939-4e81-966a-7dcb90614b6f"
      },
      "source": [
        "for iteration in range(100):\n",
        "  \n",
        "  weighted_sum = np.dot(inputs, weights)\n",
        "  \n",
        "  activated_output = sigmoid(weighted_sum)\n",
        "  \n",
        "  error = correct_outputs - activated_output\n",
        "  \n",
        "  adjustments = error * sigmoid_derivative(activated_output)\n",
        "  \n",
        "  weights += np.dot(inputs.T, adjustments)\n",
        "  \n",
        "print(weights, '\\n\\n', activated_output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.36057752]\n",
            " [-0.36057752]\n",
            " [ 0.96623867]] \n",
            "\n",
            " [[0.72436915]\n",
            " [0.64695042]\n",
            " [0.64695042]\n",
            " [0.32713869]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7sdqVs0s4x",
        "colab_type": "text"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
        "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVnDGEiL1vHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "55e57ceb-caa1-4d99-9d8e-c0b84d4ecb6c"
      },
      "source": [
        "import pandas as pd\n",
        "csv = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv'\n",
        "df = pd.read_csv(csv)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  survived  pclass     sex  ...  deck  embark_town  alive  alone\n",
              "0           0         0       3    male  ...   NaN  Southampton     no  False\n",
              "1           1         1       1  female  ...     C    Cherbourg    yes  False\n",
              "2           2         1       3  female  ...   NaN  Southampton    yes   True\n",
              "3           3         1       1  female  ...     C  Southampton    yes  False\n",
              "4           4         0       3    male  ...   NaN  Southampton     no   True\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H79BCr8H2Yn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['sex'] = df['sex'].replace({'male':1, 'female':0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXOr6iFe1vLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[['pclass', 'sex']].values\n",
        "y = np.array(df['survived'].replace({0:-1}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apF5bdDH1vJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4a0ae06b-ddd3-48b3-f556-760f2f691e9d"
      },
      "source": [
        "X"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 1],\n",
              "       [1, 0],\n",
              "       [3, 0],\n",
              "       ...,\n",
              "       [3, 0],\n",
              "       [1, 1],\n",
              "       [3, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL0EnWor3kHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "99326a22-aeb8-4684-e9c5-afb82f104400"
      },
      "source": [
        "y"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1,\n",
              "        1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1, -1,  1,  1, -1,\n",
              "       -1, -1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1,\n",
              "       -1,  1,  1, -1,  1,  1, -1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1,\n",
              "        1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1,  1, -1,  1,\n",
              "        1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1,\n",
              "       -1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "       -1, -1, -1, -1,  1, -1,  1, -1,  1,  1, -1, -1, -1, -1,  1, -1, -1,\n",
              "        1, -1, -1, -1, -1,  1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1, -1,\n",
              "       -1, -1, -1,  1, -1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1,\n",
              "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1,\n",
              "        1, -1, -1,  1, -1,  1,  1,  1,  1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
              "        1, -1, -1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1,\n",
              "       -1, -1, -1,  1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1,\n",
              "       -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
              "        1,  1,  1,  1,  1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1,\n",
              "        1, -1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1,  1,\n",
              "        1,  1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
              "        1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1,\n",
              "        1, -1,  1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1,\n",
              "        1,  1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "       -1,  1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1,\n",
              "       -1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1,  1, -1,  1,  1,\n",
              "        1, -1,  1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,  1,\n",
              "       -1, -1, -1, -1,  1, -1,  1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
              "       -1,  1,  1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1, -1,\n",
              "       -1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1, -1,  1, -1,  1,  1,\n",
              "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1,  1, -1, -1,\n",
              "       -1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1, -1, -1,  1, -1, -1, -1,\n",
              "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1, -1,  1,\n",
              "        1, -1,  1,  1, -1, -1,  1, -1,  1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
              "       -1, -1, -1,  1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1, -1,  1,\n",
              "       -1, -1,  1,  1, -1,  1,  1, -1, -1,  1,  1, -1,  1, -1,  1,  1, -1,\n",
              "       -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,\n",
              "       -1,  1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1,\n",
              "       -1,  1, -1, -1,  1,  1, -1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
              "        1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1, -1, -1, -1, -1,  1, -1,\n",
              "       -1,  1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1,  1,  1,\n",
              "       -1,  1, -1,  1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
              "       -1,  1, -1, -1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1,  1, -1,  1,\n",
              "       -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1,\n",
              "        1, -1, -1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1,\n",
              "       -1, -1,  1,  1, -1, -1,  1, -1, -1, -1,  1, -1,  1,  1, -1, -1,  1,\n",
              "       -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1, -1,  1, -1, -1,  1,\n",
              "       -1, -1,  1,  1, -1, -1,  1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1,\n",
              "        1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,\n",
              "       -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,\n",
              "       -1, -1,  1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
              "       -1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1,  1, -1,\n",
              "       -1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,\n",
              "       -1, -1, -1,  1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1, -1,  1,  1,\n",
              "       -1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1, -1,  1,  1, -1, -1, -1,\n",
              "       -1, -1, -1,  1, -1,  1, -1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W0tiX1F1hh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron(object):\n",
        "  def __init__(self, rate = .01, n_iter = 10):\n",
        "    self.rate = rate\n",
        "    self.n_iter = n_iter\n",
        "    \n",
        "  def fit(self, X, y):\n",
        "    self.weight = np.zeros(1 + X.shape[1])\n",
        "    self.errors = []\n",
        "    \n",
        "    for i in range(self.n_iter):\n",
        "      error = 0\n",
        "      for xi, target in zip(X, y):\n",
        "        delta_w = self.rate * (target - self.predict(xi))\n",
        "        self.weight[1:] += delta_w * xi\n",
        "        self.weight[0] += delta_w\n",
        "        error += int(delta_w != 0.0)\n",
        "      self.errors.append(error)\n",
        "    return self\n",
        "  \n",
        "  def net_input(self, X):\n",
        "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVHMBKKO1r7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e592565e-cfc0-40bd-fe0c-93dcb2cd7e6f"
      },
      "source": [
        "model = Perceptron()\n",
        "\n",
        "model.fit(X, y)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Perceptron at 0x7ff4acd2bb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_OSVy8c5fsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64e9b436-087d-4a7f-b346-4f584294ede6"
      },
      "source": [
        "model.predict([[3, 1]])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QR4oAW1xdyu",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}